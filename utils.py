"""
–î–æ–¥–∞—Ç–∫–æ–≤—ñ —É—Ç–∏–ª—ñ—Ç–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ –µ–∫—Å–ø–æ—Ä—Ç—É –ª—ñ–¥—ñ–≤.
"""
import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime, timedelta

DB_PATH = Path("leads.sqlite")

def get_stats() -> Dict[str, Any]:
    """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ª—ñ–¥–∞—Ö."""
    if not DB_PATH.exists():
        return {"error": "–ë–∞–∑–∞ –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"}
    
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    
    stats = {}
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ª—ñ–¥—ñ–≤
    cur.execute("SELECT COUNT(*) FROM leads")
    stats["total_leads"] = cur.fetchone()[0]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞—Ö
    cur.execute("SELECT channel, COUNT(*) FROM leads GROUP BY channel")
    stats["by_channel"] = dict(cur.fetchall())
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–æ–ª—è—Ö
    cur.execute("SELECT role_label, COUNT(*) FROM leads GROUP BY role_label")
    stats["by_role"] = dict(cur.fetchall())
    
    # –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å
    cur.execute("SELECT AVG(confidence) FROM leads WHERE role_label = 'potential_client'")
    avg_conf = cur.fetchone()[0]
    stats["avg_confidence"] = round(avg_conf, 2) if avg_conf else 0
    
    # –õ—ñ–¥–∏ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–Ω—ñ
    cur.execute("""
        SELECT DATE(created_at) as day, COUNT(*) 
        FROM leads 
        WHERE created_at >= datetime('now', '-7 days')
        GROUP BY DATE(created_at)
        ORDER BY day DESC
    """)
    stats["last_7_days"] = dict(cur.fetchall())
    
    # –¢–æ–ø –ø—Ä–∏—á–∏–Ω–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
    cur.execute("""
        SELECT reason, COUNT(*) as cnt
        FROM leads 
        WHERE role_label = 'potential_client'
        GROUP BY reason
        ORDER BY cnt DESC
        LIMIT 10
    """)
    stats["top_reasons"] = dict(cur.fetchall())
    
    conn.close()
    return stats

def export_filtered_leads(
    min_confidence: float = 0.7,
    channel: str = None,
    days_back: int = 7,
    output_file: str = "filtered_leads.csv"
) -> str:
    """–ï–∫—Å–ø–æ—Ä—Ç –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏—Ö –ª—ñ–¥—ñ–≤."""
    import csv
    
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    
    query = """
        SELECT user_id, username, display_name, channel, message_link, 
               role_label, confidence, reason, message_text, created_at
        FROM leads 
        WHERE role_label = 'potential_client' 
        AND confidence >= ?
        AND created_at >= datetime('now', '-{} days')
    """.format(days_back)
    
    params = [min_confidence]
    
    if channel:
        query += " AND channel = ?"
        params.append(channel)
    
    query += " ORDER BY confidence DESC, created_at DESC"
    
    cur.execute(query, params)
    rows = cur.fetchall()
    conn.close()
    
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([
            "user_id", "username", "display_name", "channel", "message_link",
            "role_label", "confidence", "reason", "message_text", "created_at"
        ])
        writer.writerows(rows)
    
    return output_file

def generate_outreach_templates(leads_csv: str = "filtered_leads.csv") -> str:
    """–ì–µ–Ω–µ—Ä—É—î —à–∞–±–ª–æ–Ω–∏ –¥–ª—è –∑–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ –ª—ñ–¥—ñ–≤."""
    import csv
    
    templates = []
    
    with open(leads_csv, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            username = row["username"] or row["display_name"]
            channel = row["channel"]
            reason = row["reason"]
            
            template = f"""
–ü—Ä–∏–≤—ñ—Ç, {username}! üëã

–ü–æ–º—ñ—Ç–∏–≤ —Ç–≤—ñ–π –∫–æ–º–µ–Ω—Ç–∞—Ä –≤ {channel}, –¥–µ —Ç–∏ {reason.lower()}.

–Ø –∑–∞–π–º–∞—é—Å—è [–æ–ø–∏—à–∏ —Å–≤–æ—é –ø–æ—Å–ª—É–≥—É/–ø—Ä–æ–¥—É–∫—Ç], –º–æ–∂–ª–∏–≤–æ, —Ü–µ –±—É–¥–µ —Ü—ñ–∫–∞–≤–æ –¥–ª—è —Ç–µ–±–µ.

–î–∂–µ—Ä–µ–ª–æ: {row['message_link']}

–Ø–∫—â–æ –Ω–µ —Ü—ñ–∫–∞–≤–∏—Ç—å - –ø—Ä–æ—Å—Ç–æ —ñ–≥–Ω–æ—Ä—É–π —Ü–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è üôÇ

---
""".strip()
            
            templates.append({
                "user": username,
                "channel": channel,
                "template": template
            })
    
    # –ó–±–µ—Ä–µ–≥—Ç–∏ —É —Ñ–∞–π–ª
    output_file = "outreach_templates.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        for t in templates:
            f.write(f"=== {t['user']} ({t['channel']}) ===\n")
            f.write(t['template'])
            f.write("\n\n" + "="*50 + "\n\n")
    
    return output_file

def cleanup_old_leads(days_to_keep: int = 30) -> int:
    """–í–∏–¥–∞–ª–∏—Ç–∏ —Å—Ç–∞—Ä—ñ –ª—ñ–¥–∏ –¥–ª—è GDPR compliance."""
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    
    cur.execute("""
        DELETE FROM leads 
        WHERE created_at < datetime('now', '-{} days')
    """.format(days_to_keep))
    
    deleted_count = cur.rowcount
    conn.commit()
    conn.close()
    
    return deleted_count

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–£—Ç–∏–ª—ñ—Ç–∏ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –ª—ñ–¥–∞–º–∏")
    parser.add_argument("--stats", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
    parser.add_argument("--export", action="store_true", help="–ï–∫—Å–ø–æ—Ä—Ç –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏—Ö –ª—ñ–¥—ñ–≤")
    parser.add_argument("--templates", action="store_true", help="–ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —à–∞–±–ª–æ–Ω–∏ –∑–≤–µ—Ä–Ω–µ–Ω—å")
    parser.add_argument("--cleanup", type=int, help="–í–∏–¥–∞–ª–∏—Ç–∏ –ª—ñ–¥–∏ —Å—Ç–∞—Ä—à—ñ –∑–∞ N –¥–Ω—ñ–≤")
    parser.add_argument("--min-confidence", type=float, default=0.7, help="–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å")
    parser.add_argument("--channel", help="–§—ñ–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª—É")
    parser.add_argument("--days", type=int, default=7, help="–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ –Ω–∞–∑–∞–¥")
    
    args = parser.parse_args()
    
    if args.stats:
        stats = get_stats()
        print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    if args.export:
        file = export_filtered_leads(
            min_confidence=args.min_confidence,
            channel=args.channel,
            days_back=args.days
        )
        print(f"–ï–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —É {file}")
    
    if args.templates:
        file = generate_outreach_templates()
        print(f"–®–∞–±–ª–æ–Ω–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {file}")
    
    if args.cleanup:
        deleted = cleanup_old_leads(args.cleanup)
        print(f"–í–∏–¥–∞–ª–µ–Ω–æ {deleted} —Å—Ç–∞—Ä–∏—Ö –ª—ñ–¥—ñ–≤")